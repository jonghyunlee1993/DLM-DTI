{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65edfec5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tokenizer\n",
      "vocab size: 30\n",
      "special tokens: ['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "protein_tokenizer = BertTokenizer.from_pretrained(\"data/target/protein_tokenizer\", do_lower_case=False)\n",
    "vocab_size = len(protein_tokenizer.get_vocab().keys())\n",
    "\n",
    "print(f\"load tokenizer\\nvocab size: {vocab_size}\\nspecial tokens: {protein_tokenizer.all_special_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22cdd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "X_train: 1193\n",
      "X_valid: 133\n",
      "X_test: 148\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "if not os.path.exists(\"data/target/X.pkl\"):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    with open(\"data/target/target_sequences.pkl\", 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "        print(f\"load dataset ... # of data: {len(data)}\")\n",
    "    \n",
    "    X_train, X_test = train_test_split(data, test_size=0.1, random_state=42, shuffle=True)\n",
    "    X_train, X_valid = train_test_split(X_train, test_size=0.1, random_state=42, shuffle=True)\n",
    "    \n",
    "    with open(\"data/target/X.pkl\", \"wb\") as f:\n",
    "        pickle.dump([X_train, X_valid, X_test], f)\n",
    "else:\n",
    "    with open(\"data/target/X.pkl\", \"rb\") as f:\n",
    "        X_train, X_valid, X_test = pickle.load(f)\n",
    "        \n",
    "print(f\"load dataset\\nX_train: {len(X_train)}\\nX_valid: {len(X_valid)}\\nX_test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b20924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(np.array([len(x) for x in X_train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11933b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "max_seq_len = 1024\n",
    "\n",
    "class MaskedLMDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "    def encode(self, data):\n",
    "        return self.tokenizer.encode(\" \".join(data), max_length=self.max_length, truncation=True)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.encode(self.data[idx]), dtype=torch.long)\n",
    "    \n",
    "    \n",
    "data_collator_train = DataCollatorForLanguageModeling(\n",
    "    tokenizer=protein_tokenizer, mlm=True, mlm_probability=0.3\n",
    ")\n",
    "\n",
    "data_collator_valid = DataCollatorForLanguageModeling(\n",
    "    tokenizer=protein_tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "train_dataset = MaskedLMDataset(X_train, protein_tokenizer, max_length=max_seq_len)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, collate_fn=data_collator_train, \n",
    "                              num_workers=3, pin_memory=False, prefetch_factor=4, \n",
    "                              shuffle=True)\n",
    "\n",
    "valid_dataset = MaskedLMDataset(X_valid, protein_tokenizer, max_length=max_seq_len)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=6, collate_fn=data_collator_valid, \n",
    "                              num_workers=3, pin_memory=False, prefetch_factor=4)\n",
    "\n",
    "test_dataset = MaskedLMDataset(X_test, protein_tokenizer, max_length=max_seq_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=6, collate_fn=data_collator_valid, \n",
    "                             num_workers=3, pin_memory=False, prefetch_factor=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba17e5ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import torchmetrics.functional as FM\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertForMaskedLM\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "class Bert(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "        for param in self.model.base_model.encoder.layer[0:-1].parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, labels):\n",
    "        return self.model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "       \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        output = self(input_ids, labels)\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        \n",
    "        self.log('train_loss', float(loss), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", FM.accuracy(preds[labels > 0], labels[labels > 0]), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        output = self(input_ids, labels)\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        \n",
    "        self.log('valid_loss', float(loss), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"valid_accuracy\", FM.accuracy(preds[labels > 0], labels[labels > 0]), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        output = self(input_ids, labels)\n",
    "\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        \n",
    "        self.log('test_loss', float(loss), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_accuracy\", FM.accuracy(preds[labels > 0], labels[labels > 0]), on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
    "    \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "    \n",
    "    \n",
    "model = Bert()\n",
    "callbacks = [\n",
    "    ModelCheckpoint(monitor='valid_loss', save_top_k=5, dirpath='weights/protein_bert_pretraining_masking_rate_30', filename='protein_bert-{epoch:03d}-{valid_loss:.4f}-{valid_accuracy:.4f}'),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=50, gpus=1, enable_progress_bar=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9b835b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | BertForMaskedLM | 417 M \n",
      "------------------------------------------\n",
      "51.8 M    Trainable params\n",
      "365 M     Non-trainable params\n",
      "417 M     Total params\n",
      "1,668.248 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9cd41e54ff46a6a16cda4723e146fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (1024) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:768\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 768\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:721\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:809\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    805\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    807\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    808\u001b[0m )\n\u001b[0;32m--> 809\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1234\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1234\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1236\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1321\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1343\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1411\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1411\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:154\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    153\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 154\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:127\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:222\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1763\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mBert.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     44\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 46\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     49\u001b[0m logits \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mBert.forward\u001b[0;34m(self, input_ids, labels)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, labels):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1350\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1350\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1365\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1017\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1008\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1010\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1011\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1012\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1016\u001b[0m )\n\u001b[0;32m-> 1017\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1030\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:606\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    597\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    598\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    599\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    604\u001b[0m     )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:534\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    531\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    532\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 534\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:547\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    546\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 547\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:462\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    460\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    461\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 462\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (1024) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6e11a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/ubuntu/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbb0f9f5f6946d79b5cabce847119e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.7976479530334473, 'test_loss': 0.6685153841972351}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6685153841972351, 'test_accuracy': 0.7976479530334473}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without finetuning\n",
    "# trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d965791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3f7668e2a348a69170619ea3fc80d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.8568375110626221, 'test_loss': 0.5093826055526733}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5093826055526733, 'test_accuracy': 0.8568375110626221}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with finetuning\n",
    "ckpt_fname = \"protein_bert-epoch=043-valid_loss=0.5893-valid_accuracy=0.8369.ckpt\"\n",
    "model = Bert().load_from_checkpoint(\"weights/protein_bert_pretraining_masking_rate_30/\" + ckpt_fname)\n",
    "\n",
    "trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65907008",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.base_model.save_pretrained(\"weights/protein_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a5082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
